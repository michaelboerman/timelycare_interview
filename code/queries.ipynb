{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_to_dataframe(file_path, worksheet_name):\n",
    "    \"\"\"\n",
    "    Reads the specified worksheet from an Excel file and returns a Pandas data frame.\n",
    "\n",
    "    Arguments:\n",
    "        file_path (str): The path to the Excel file.\n",
    "        worksheet_name (str): The name of the worksheet to read.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The data frame containing the data from the specified worksheet.\n",
    "    \"\"\"\n",
    "    # Read the Excel file\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "\n",
    "    # Read the specified worksheet into a data frame\n",
    "    df = pd.read_excel(xls, worksheet_name)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string columns to lowercase\n",
    "# to make future where clauses easier\n",
    "def convert_all_strings_to_lc(df):\n",
    "    string_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[string_cols] = df[string_cols].apply(lambda x: x.str.lower() if x.name in string_cols else x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string field of yyyy-mm-dd to datetime field.\n",
    "def convert_date_column_to_datetime(table_name, column_name, db_name=\"timelycare\"):\n",
    "\n",
    "    from sqlalchemy import create_engine, MetaData, Table, Column, Date, String\n",
    "\n",
    "    engine = create_engine(f'sqlite:///{db_name}.db', echo=False)\n",
    "    conn = engine.connect()\n",
    "\n",
    "    # Rename the original table\n",
    "    conn.execute(f\"ALTER TABLE {table_name} RENAME TO {table_name}_old\")\n",
    "\n",
    "    # Create a new table with the same schema, but with the date column as a date type\n",
    "    metadata = MetaData()\n",
    "    old_table = Table(f\"{table_name}_old\", metadata, autoload=True, autoload_with=engine)\n",
    "    new_table = Table(table_name, metadata,\n",
    "        *[Column(c.name.lower(), Date()) if c.name == col_name else Column(c.name.lower(), String()) for c in old_table.columns],\n",
    "    )\n",
    "    new_table.create(engine)\n",
    "\n",
    "    # Copy the data from the old table to the new table, transforming the date column\n",
    "    select_stmt = old_table.select()\n",
    "    insert_stmt = new_table.insert().from_select(\n",
    "        [c.name.lower() for c in new_table.columns], select_stmt\n",
    "    )\n",
    "    insert_stmt = insert_stmt.on_conflict_do_nothing()\n",
    "    conn.execute(insert_stmt)\n",
    "\n",
    "    # Drop the old table\n",
    "    conn.execute(f\"DROP TABLE {table_name}_old\")\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_upload_json_format(i, df, table_name, engine, json_columns):\n",
    "    if json_columns is not None and json_columns[i] is not None:\n",
    "        for json_col in json_columns:\n",
    "            if json_col in df.columns:\n",
    "                \n",
    "                # Parse the JSON data and store it in a new data frame\n",
    "                json_data = df[json_col].apply(json.loads)\n",
    "                json_df = pd.json_normalize(json_data.explode())\n",
    "\n",
    "                # Write the JSON data frame to a new table\n",
    "                json_table_name = json_col\n",
    "                json_df.to_sql(json_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "                # convert_date_column_to_datetime(table_name, json_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_database(data_frames, table_names, json_columns=None):\n",
    "    \"\"\"\n",
    "    Writes a list of Pandas data frames to local database tables using SQLAlchemy. If a column name is provided as\n",
    "    json_column, the contents of that column will be parsed as a JSON file and uploaded to a new table with\n",
    "    the same name as the column.\n",
    "\n",
    "    Args:\n",
    "        data_frames (list of pandas.DataFrame): The data frames to write to the database.\n",
    "        table_names (list of str): The names of the tables to create or overwrite in the database.\n",
    "        json_columns (list of str): The names of the columns to parse as JSON files and upload to new tables.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a SQLAlchemy engine for the local database\n",
    "    engine = create_engine('sqlite:///timelycare.db')\n",
    "\n",
    "    # Iterate over each data frame and table name\n",
    "    for i, (df, table_name) in enumerate(zip(data_frames, table_names)):\n",
    "\n",
    "        df = convert_all_strings_to_lc(df)\n",
    "        \n",
    "        # if json column, pop it out and upload separate.\n",
    "        parse_upload_json_format(i, df, table_name, engine, json_columns)                    \n",
    "                    \n",
    "        # Write the remaining data frame to the specified database table\n",
    "        df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "file_path       = \"../data/prompt.xlsx\"\n",
    "worksheet_names = [\"visit_table\", \"member_table\", \"provider_table\"]\n",
    "table_names     = [\"visit\", \"member\", \"provider\"]\n",
    "json_columns    = [None, None, \"License\"]\n",
    "tables_to_create = []\n",
    "\n",
    "# Read the specified worksheets into data frames\n",
    "data_frames = [read_excel_to_dataframe(file_path, sheet) for sheet in worksheet_names]\n",
    "\n",
    "# Write the data frames to the database, with the specified JSON columns parsed into new tables\n",
    "write_dataframes_to_database(data_frames, table_names, json_columns)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using https://jupyter-tutorial.readthedocs.io/en/stable/data-processing/postgresql/ipython-sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (988781342.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[71], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    SELECT * FROM \"visit_table\"\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "\n",
    "# Connect to the local database\n",
    "%sql sqlite:///timelycare.db\n",
    "\n",
    "%%sql\n",
    "SELECT * FROM visit_table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
