{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_to_dataframe(file_path, worksheet_name):\n",
    "    \"\"\"\n",
    "    Reads the specified worksheet from an Excel file and returns a Pandas data frame.\n",
    "\n",
    "    Arguments:\n",
    "        file_path (str): The path to the Excel file.\n",
    "        worksheet_name (str): The name of the worksheet to read.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The data frame containing the data from the specified worksheet.\n",
    "    \"\"\"\n",
    "    # Read the Excel file\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "\n",
    "    # Read the specified worksheet into a data frame\n",
    "    df = pd.read_excel(xls, worksheet_name)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string columns to lowercase\n",
    "# to make future where clauses easier\n",
    "def convert_all_strings_to_lc(df):\n",
    "    string_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[string_cols] = df[string_cols].apply(lambda x: x.str.lower() if x.name in string_cols else x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string field of yyyy-mm-dd to datetime field.\n",
    "def convert_date_column_to_datetime(table_name, column_name, db_name=\"timelycare\"):\n",
    "\n",
    "    from sqlalchemy import create_engine, MetaData, Table, Column, Date, String\n",
    "\n",
    "    engine = create_engine(f'sqlite:///{db_name}.db', echo=False)\n",
    "    conn = engine.connect()\n",
    "\n",
    "    # Rename the original table\n",
    "    conn.execute(f\"ALTER TABLE {table_name} RENAME TO {table_name}_old\")\n",
    "\n",
    "    # Create a new table with the same schema, but with the date column as a date type\n",
    "    metadata = MetaData()\n",
    "    old_table = Table(f\"{table_name}_old\", metadata, autoload=True, autoload_with=engine)\n",
    "    new_table = Table(table_name, metadata,\n",
    "        *[Column(c.name.lower(), Date()) if c.name == col_name else Column(c.name.lower(), String()) for c in old_table.columns],\n",
    "    )\n",
    "    new_table.create(engine)\n",
    "\n",
    "    # Copy the data from the old table to the new table, transforming the date column\n",
    "    select_stmt = old_table.select()\n",
    "    insert_stmt = new_table.insert().from_select(\n",
    "        [c.name.lower() for c in new_table.columns], select_stmt\n",
    "    )\n",
    "    insert_stmt = insert_stmt.on_conflict_do_nothing()\n",
    "    conn.execute(insert_stmt)\n",
    "\n",
    "    # Drop the old table\n",
    "    conn.execute(f\"DROP TABLE {table_name}_old\")\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_upload_json_format(i, df, table_name, engine, json_columns):\n",
    "    if json_columns is not None and json_columns[i] is not None:\n",
    "        for json_col in json_columns:\n",
    "            if json_col in df.columns:\n",
    "                \n",
    "                # Parse the JSON data and store it in a new data frame\n",
    "                json_data = df[json_col].apply(json.loads)\n",
    "                json_df = pd.json_normalize(json_data.explode())\n",
    "\n",
    "                # Write the JSON data frame to a new table\n",
    "                json_table_name = json_col\n",
    "                json_df.to_sql(json_table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "                # convert_date_column_to_datetime(table_name, json_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_database(data_frames, table_names, json_columns=None):\n",
    "    \"\"\"\n",
    "    Writes a list of Pandas data frames to local database tables using SQLAlchemy. \n",
    "    If a column name is provided as json_column, the contents of that column will be parsed \n",
    "    as a JSON file and uploaded to a new table with the same name as the column.\n",
    "\n",
    "    Arguments:\n",
    "        data_frames (list of pd.DataFrames): The data frames to write to the database.\n",
    "        table_names (list of str): The names of the tables to create or overwrite in the database.\n",
    "        json_columns (list of str): The names of the columns to parse as JSON files and upload to new tables.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a SQLAlchemy engine for the local database\n",
    "    engine = create_engine('sqlite:///timelycare.db')\n",
    "\n",
    "    # Iterate over each data frame and table name\n",
    "    for i, (df, table_name) in enumerate(zip(data_frames, table_names)):\n",
    "\n",
    "        df = convert_all_strings_to_lc(df)\n",
    "        \n",
    "        # if json column, pop it out and upload separate.\n",
    "        parse_upload_json_format(i, df, table_name, engine, json_columns)                    \n",
    "                    \n",
    "        # Write the remaining data frame to the specified database table\n",
    "        df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "file_path       = \"../data/prompt.xlsx\"\n",
    "worksheet_names = [\"visit_table\", \"member_table\", \"provider_table\"]\n",
    "table_names     = [\"visit\", \"member\", \"provider\"]\n",
    "json_columns    = [None, None, \"License\"]\n",
    "tables_to_create = []\n",
    "\n",
    "# Read the specified worksheets into data frames\n",
    "data_frames = [read_excel_to_dataframe(file_path, sheet) for sheet in worksheet_names]\n",
    "\n",
    "# Write the data frames to the database, with the specified JSON columns parsed into new tables\n",
    "write_dataframes_to_database(data_frames, table_names, json_columns)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using https://jupyter-tutorial.readthedocs.io/en/stable/data-processing/postgresql/ipython-sql.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Query\n",
    "*Prompt*: We're noticing a data quality issue and want you to investigate. \n",
    "\n",
    "1. What's the total number of visits that cannot occur because the provider was double-booked at the same time?  \n",
    "\n",
    "2. What is the total count that can not continue because the provider didn't have a valid license in the member's state?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Approach*: \n",
    "\n",
    "1. I will need to find all the the instances in which a provider had a scheduled start time that occured before their prior session's end time.\n",
    "\n",
    "2. I will need to use the \"lisence\" table (spin off of the json table I created) joined on teh member table to find all the instances in which a provider *can* provide services. Then I'll filter the main table for each of these combinations. I'll then subtract from the total row count to find the number that *can't*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to the local database\n",
    "%sql sqlite:///timelycare.db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///timelycare.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>session_id</th>\n",
       "            <th>provider_id</th>\n",
       "            <th>started_date_time</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>7</td>\n",
       "            <td>3</td>\n",
       "            <td>2023-01-15 05:48:53.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8</td>\n",
       "            <td>3</td>\n",
       "            <td>2023-01-15 05:15:49.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>13</td>\n",
       "            <td>3</td>\n",
       "            <td>2023-01-14 19:58:02.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19</td>\n",
       "            <td>1</td>\n",
       "            <td>2023-01-15 20:00:11.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>22</td>\n",
       "            <td>3</td>\n",
       "            <td>2023-01-15 19:57:22.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>25</td>\n",
       "            <td>5</td>\n",
       "            <td>2023-01-15 19:50:00.000000</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(7, 3, '2023-01-15 05:48:53.000000'),\n",
       " (8, 3, '2023-01-15 05:15:49.000000'),\n",
       " (13, 3, '2023-01-14 19:58:02.000000'),\n",
       " (19, 1, '2023-01-15 20:00:11.000000'),\n",
       " (22, 3, '2023-01-15 19:57:22.000000'),\n",
       " (25, 5, '2023-01-15 19:50:00.000000')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "with lag_table as (\n",
    "  SELECT \n",
    "    id as session_id,\n",
    "    provider_id, \n",
    "    LAG(provider_id) OVER (ORDER BY scheduled_date_time) AS prev_provider_id,\n",
    "    LAG(ended_date_time) OVER (ORDER BY scheduled_date_time) as prev_end_time,\n",
    "    scheduled_date_time, \n",
    "    started_date_time,\n",
    "    member_id as current_member_id,\n",
    "    LAG(member_id) OVER (ORDER BY scheduled_date_time) AS prev_member_id\n",
    "  FROM visit\n",
    ")\n",
    "\n",
    "select session_id, provider_id, started_date_time\n",
    "  FROM lag_table\n",
    " WHERE provider_id = prev_provider_id\n",
    "       and current_member_id != prev_member_id -- assume that if ==, then duplicate record, not truly a double-book.\n",
    "order by session_id, provider_id, scheduled_date_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Q1:** There are 6 instances. \n",
    "\n",
    "One of them, however, does not have a previous end time. \n",
    "This is the duplicate session for Provider 5. \n",
    "Since we are investigating potential erroneous data, I choose to include it, because it seems likely that this data is erroneous."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python version of Q1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///timelycare.db\n",
      "Done.\n",
      " * sqlite:///timelycare.db\n",
      "Done.\n",
      " * sqlite:///timelycare.db\n",
      "Done.\n",
      " * sqlite:///timelycare.db\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "visit_query = %sql SELECT * FROM visit\n",
    "visit_df = visit_query.DataFrame()\n",
    "\n",
    "member_query =  %sql SELECT * FROM member\n",
    "member_df =  member_query.DataFrame()\n",
    "\n",
    "provider_query = %sql SELECT * FROM provider\n",
    "provider_df =  provider_query.DataFrame()\n",
    "\n",
    "license_df_df_query = %sql SELECT * FROM license\n",
    "license_df = license_query.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>scheduled_date_time</th>\n",
       "      <th>prev_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-15 05:11:08.000000</td>\n",
       "      <td>2023-01-15 06:04:47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-15 04:52:18.000000</td>\n",
       "      <td>2023-01-15 05:40:46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-14 19:45:00.000000</td>\n",
       "      <td>2023-01-14 20:16:43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-15 20:00:00.000000</td>\n",
       "      <td>2023-01-15 20:43:43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-15 19:47:07.000000</td>\n",
       "      <td>2023-01-15 20:38:02.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id  provider_id         scheduled_date_time  \\\n",
       "7            8            3  2023-01-15 05:11:08.000000   \n",
       "8            9            3  2023-01-15 04:52:18.000000   \n",
       "13          14            3  2023-01-14 19:45:00.000000   \n",
       "18          19            1  2023-01-15 20:00:00.000000   \n",
       "22          23            3  2023-01-15 19:47:07.000000   \n",
       "\n",
       "                 prev_end_time  \n",
       "7   2023-01-15 06:04:47.000000  \n",
       "8   2023-01-15 05:40:46.000000  \n",
       "13  2023-01-14 20:16:43.000000  \n",
       "18  2023-01-15 20:43:43.000000  \n",
       "22  2023-01-15 20:38:02.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lag_table = visit_df[[\"id\", \"provider_id\", \"scheduled_date_time\", \"member_id\", \"ended_date_time\"]]\n",
    "lag_table.columns = [\"session_id\", \"provider_id\", \"scheduled_date_time\", \"current_member_id\", \"prev_end_time\"]\n",
    "\n",
    "lag_table.loc[:, \"prev_provider_id\"] = lag_table[\"provider_id\"].shift(1)\n",
    "lag_table.loc[:, \"prev_end_time\"] = lag_table[\"prev_end_time\"].shift(1)\n",
    "lag_table.loc[:, \"prev_member_id\"] = lag_table[\"current_member_id\"].shift(1)\n",
    "\n",
    "result = lag_table[(lag_table[\"provider_id\"] == lag_table[\"prev_provider_id\"]) & (lag_table[\"current_member_id\"] != lag_table[\"prev_member_id\"])]\n",
    "result = result[[\"session_id\", \"provider_id\", \"scheduled_date_time\", \"prev_end_time\"]].sort_values(by=[\"session_id\", \"provider_id\", \"scheduled_date_time\"])\n",
    "\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sql version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///timelycare.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th>\n",
       "            <th>member_id</th>\n",
       "            <th>provider_id</th>\n",
       "            <th>service_line</th>\n",
       "            <th>scheduled_date_time</th>\n",
       "            <th>started_date_time</th>\n",
       "            <th>ended_date_time</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2</td>\n",
       "            <td>1</td>\n",
       "            <td>4</td>\n",
       "            <td>hc</td>\n",
       "            <td>2023-01-17 05:00:00.000000</td>\n",
       "            <td>2023-01-17 05:01:21.000000</td>\n",
       "            <td>2023-01-17 05:41:50.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>17</td>\n",
       "            <td>5</td>\n",
       "            <td>4</td>\n",
       "            <td>hc</td>\n",
       "            <td>2023-01-14 19:33:59.000000</td>\n",
       "            <td>2023-01-14 19:40:29.000000</td>\n",
       "            <td>2023-01-14 19:43:28.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>20</td>\n",
       "            <td>3</td>\n",
       "            <td>2</td>\n",
       "            <td>pysch</td>\n",
       "            <td>2023-01-15 20:00:00.000000</td>\n",
       "            <td>2023-01-15 20:00:03.000000</td>\n",
       "            <td>2023-01-15 21:01:03.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21</td>\n",
       "            <td>5</td>\n",
       "            <td>4</td>\n",
       "            <td>hc</td>\n",
       "            <td>2023-01-15 20:00:00.000000</td>\n",
       "            <td>2023-01-15 19:58:48.000000</td>\n",
       "            <td>2023-01-15 21:01:03.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>24</td>\n",
       "            <td>3</td>\n",
       "            <td>4</td>\n",
       "            <td>hc</td>\n",
       "            <td>2023-01-17 04:06:08.000000</td>\n",
       "            <td>2023-01-17 04:14:55.000000</td>\n",
       "            <td>2023-01-17 04:27:11.000000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>25</td>\n",
       "            <td>8</td>\n",
       "            <td>5</td>\n",
       "            <td>ther</td>\n",
       "            <td>2023-01-12 19:47:07.000000</td>\n",
       "            <td>2023-01-15 19:50:00.000000</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2, 1, 4, 'hc', '2023-01-17 05:00:00.000000', '2023-01-17 05:01:21.000000', '2023-01-17 05:41:50.000000'),\n",
       " (17, 5, 4, 'hc', '2023-01-14 19:33:59.000000', '2023-01-14 19:40:29.000000', '2023-01-14 19:43:28.000000'),\n",
       " (20, 3, 2, 'pysch', '2023-01-15 20:00:00.000000', '2023-01-15 20:00:03.000000', '2023-01-15 21:01:03.000000'),\n",
       " (21, 5, 4, 'hc', '2023-01-15 20:00:00.000000', '2023-01-15 19:58:48.000000', '2023-01-15 21:01:03.000000'),\n",
       " (24, 3, 4, 'hc', '2023-01-17 04:06:08.000000', '2023-01-17 04:14:55.000000', '2023-01-17 04:27:11.000000'),\n",
       " (25, 8, 5, 'ther', '2023-01-12 19:47:07.000000', '2023-01-15 19:50:00.000000', None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM visit\n",
    "WHERE provider_id NOT IN (\n",
    "    SELECT _id as provider_id\n",
    "    FROM license\n",
    "    WHERE state = (\n",
    "        SELECT visit_state\n",
    "        FROM member\n",
    "        WHERE member.id = visit.member_id\n",
    "    )\n",
    ");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total count is 6. I chose to show all data instead of showing the total count. To show the total count (desireable, for instance, if the row count was very high), replace the first line with `select count(*) as total_count`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>member_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>service_line</th>\n",
       "      <th>scheduled_date_time</th>\n",
       "      <th>started_date_time</th>\n",
       "      <th>ended_date_time</th>\n",
       "      <th>id_y</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>visit_state</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>state</th>\n",
       "      <th>active</th>\n",
       "      <th>exp_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_x, member_id, provider_id, service_line, scheduled_date_time, started_date_time, ended_date_time, id_y, gender, age, visit_state, _id, type, state, active, exp_date]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_df['provider_id'] = license_df['_id'].astype('object')\n",
    "\n",
    "\n",
    "# Join visit and member tables on member_id column\n",
    "visit_member = pd.merge(visit_df, member_df, left_on='member_id', right_on='id')\n",
    "visit_member['provider_id'] = visit_member['provider_id'].astype('object')\n",
    "\n",
    "\n",
    "# Join license table with the above table on _id and visit_state columns\n",
    "visit_member_license = pd.merge(visit_member, license_df, left_on=['provider_id', 'visit_state'], right_on=['provider_id', 'state'], how='left')\n",
    "\n",
    "# Filter the rows where _id is null (not found in license table)\n",
    "result = visit_member_license[visit_member_license['provider_id'].isnull()]\n",
    "\n",
    "# Get the count of rows\n",
    "total_count = len(result)\n",
    "total_count\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't get the python version to work: either I'd have the full 25 rows or 0 rows. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
